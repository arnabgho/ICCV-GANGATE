\begin{abstract}
\vspace{-1mm}
Effectively incorporating low-dimensional conditioning is a crucial, yet relatively unexplored, aspect of multiclass, multimodal, and multitask image-to-image translation.
% Effectively incorporating low-dimensional conditioning information is an important, yet relatively unexplored, aspect of image generation, enabling multiclass, multimodal, and multitask image-to-image translation.
We systematically investigate variants of injecting conditioning into GAN architectures. We propose a soft-gating mechanism, which learns to ``select" which parts of a ResNet~\cite{he2016deep} are used, based on the conditioner.
% We propose a mechanism to learn these injections through ``gating" over residual blocks.
% The proposed technique
% gating function
% enables plausible generations in multiclass scenarios, where commonly-used naive concatenation fails.
% We show that learning a gating function allows us to generate plausible samples in multiclass image-to-image translation tasks.
We validate on a challenging outline-to-image task, mapping from a sparse sketch with no internal structure. Class conditioning is especially important, and the soft-gating mechanism enables plausible generations where naive concatenation fails.
The method is also effective on standard sketch-to-image and day-to-night tasks.
Additionally, the gating better fulfills the InfoGAN~\cite{chen2016infogan} objective, maximizing mutual information between the output and the conditioner,
% in an effective way,
enabling diverse generations for image-to-image translation. 
% We demonstrate that our approach is able to generate high quality multiclass image translations, outperforming prior state-of-the-art methods.

%We propose a method that allows us to generate images belonging to multiple domains using a single network.
%Our approach is based on a GAN framework with two separate branches, a fully residual generator and discriminator, and a separate smaller gating network.
%The gating network selects residual blocks from the generator and discriminator based on some conditioning.
%We show that such an approach is able to produce high quality multi-class image generation, both in an class-conditioned image-to-image translation task, as well as in an unsupervised image generation task where diversity is learned.
%This method allows for significantly smaller model sizes than previous multi-class approaches by taking advantage of similarities across classes. 
%We analyze our gating network to show that it leads to subnetworks based on the residual blocks that are active for a particular class.
%This approach as well as helps inject low dimensional information into a network more effectively than just concatenating channel-wise after replication to match the image dimension. 
%Information theoretic results also show it to be a much stronger form of conditioning than naive concatenation. 
%We apply our approach on a novel setting of multi-class outline-to-image generation, where baseline solutions fail to generate good results, while our model successfully tackles the multi-class image generation setting. 
\end{abstract}