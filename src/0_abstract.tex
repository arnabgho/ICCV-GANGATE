\begin{abstract}
We propose a new task involving GAN based recommender that helps novice users to interactively synthesize images of simple objects merely using partial sketches.
The user starts with an extremely sparse sketch for the object category as an input, and the network then recommends its plausible completion and shows corresponding synthesized image. This allows the user to interactively take feedback from the network, edit the input sketch, and synthesize the desired object.
In order to be able to use a single model for a wide array of object classes, we introduce a gating based approach for class conditioning, which allows us to generate distinct classes without feature mixing, from a single generator network.

%Effectively incorporating low-dimensional conditioning is a crucial, yet relatively unexplored, aspect of multiclass, multimodal, and multitask image-to-image translation.
%We systematically investigate variants of injecting conditioning into GAN architectures. We propose a soft-gating mechanism, which learns to ``select" which parts of a ResNet~\cite{he2016deep} are used, based on the conditioner.
%We validate on a challenging outline-to-image task, mapping from a sparse sketch with no internal structure. 
%Class conditioning is especially important, and the soft-gating mechanism enables plausible generations where naive concatenation fails.
%The method is also effective on standard sketch-to-image and day-to-night tasks.
%Additionally, the gating better fulfills the InfoGAN~\cite{chen2016infogan} objective, maximizing mutual information between the output and the conditioner,
% in an effective way,
%enabling diverse generations for image-to-image translation. 
% We demonstrate that our approach is able to generate high quality multiclass image translations, outperforming prior state-of-the-art methods.

%We propose a method that allows us to generate images belonging to multiple domains using a single network.
%Our approach is based on a GAN framework with two separate branches, a fully residual generator and discriminator, and a separate smaller gating network.
%The gating network selects residual blocks from the generator and discriminator based on some conditioning.
%We show that such an approach is able to produce high quality multi-class image generation, both in an class-conditioned image-to-image translation task, as well as in an unsupervised image generation task where diversity is learned.
%This method allows for significantly smaller model sizes than previous multi-class approaches by taking advantage of similarities across classes. 
%We analyze our gating network to show that it leads to subnetworks based on the residual blocks that are active for a particular class.
%This approach as well as helps inject low dimensional information into a network more effectively than just concatenating channel-wise after replication to match the image dimension. 
%Information theoretic results also show it to be a much stronger form of conditioning than naive concatenation. 
%We apply our approach on a novel setting of multi-class outline-to-image generation, where baseline solutions fail to generate good results, while our model successfully tackles the multi-class image generation setting. 
\end{abstract}