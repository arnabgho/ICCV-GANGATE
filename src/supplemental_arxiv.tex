
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth,trim={2.6cm 0 1.8cm 0},clip]{paper_images/mog.pdf}
    % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
    \caption{{\bf 1D Mixture of Gaussians.} {\bf (Left)} Samples from a residual network (blue-dotted) closely approximate the training distribution (black). {\bf (Mid)} Removing one residual block removes one mode of the predicted distribution. {\bf (Right)} Removing two blocks drops two modes. Note that samples stay mostly ``on-manifold" of the ground truth distribution.
    %\vspace{-2mm}
    }\label{fig:onedexperiment}
    %\vspace{-3mm}
\end{figure*}

\section{Insights on Gating Mechanism}
We demonstrate the intuition behind our gating mechanism with a toy experiment where a generative network models a 1D mixture of Gaussians, comprised of five components~\figref{fig:onedexperiment}. 
For this test, the generator and discriminator architectures consist of only residual blocks, where each residual block is composed of fully connected layers. 
% Additional details are in the supplementary material. 
%
The generator is conditioned on a latent vector $z$ and is trained to approximate the distribution, as seen in Fig.~\ref{fig:onedexperiment} (left). 
Removing a single residual block, in the spirit of~\cite{veit2016residual}, leads to the disappearance of a mode from the predicted distribution. 
Removal of another block leads to further removal of another mode, as seen in Fig.~\ref{fig:onedexperiment}  (mid, right). 
This experiment suggests that residual blocks arrange themselves  naturally into modeling parts of a distribution, which motivates our use of a gating network where the network learns which blocks (or alternatively, which channels) to attend to for each object class. %It increases the participation of the condition $({\bf y})$ in the generation process which in turn helps the network to effectively disentangle different object classes.

\subsection{Network Architecture}
% \ow{but why was this architecture chosen? did the normal ones in madgan/mode gan not work? what motivates the skinny resnet?} 
The architecture was designed to reproduce some of the experiments performed by \cite{veit2016residual} by removing blocks and observing the resulting generated distribution.
While our network is deeper (16 layers of residual blocks) than required for similar experiments e.g., in MAD-GAN \cite{ghosh2017multi}, Mode Regularized GAN \cite{che2016mode} and Unrolled GAN \cite{metz2017unrolledGAN}, we use only 4 neurons in each residual block of the generator and discriminator (Tables~\ref{table:1d_G}~\&~\ref{table:1d_D}) compared to fully connected versions in which there consisted of connections between 256 neurons in the preceding layer to 256 neurons in the current layer. Thus although the number of parameters is much lower, the network learns the distribution quite accurately. The architecture used in this experiment inspired the design of the skinny Resnet architecture as described later.

% \begin{table}[ht]
% \caption{\textbf{Generator for 1D setting}} % title of Table
% \centering % used for centering table
% \begin{tabular}{c c} % centered columns (4 columns)
% \hline\hline %inserts double horizontal lines
% layer & num layers\\%heading
% \hline % inserts single horizontal line
% Linear(10,4) & 1\\ % inserting body of the table
% ResBlock(4) & 16 \\
% Linear(4,1) & 1 \\
% \hline %inserts single line
% \end{tabular}
% \label{table:1d_G} % is used to refer this table in the text
% \end{table}

% \begin{table}[ht]
% \caption{\textbf{Discriminator for 1D setting}} % title of Table
% \centering % used for centering table
% \begin{tabular}{c c} % centered columns (4 columns)
% \hline\hline %inserts double horizontal lines
% layer & num layers\\%heading
% \hline % inserts single horizontal line
% Linear(1,4) & 1\\ % inserting body of the table
% ResBlock(4) & 16 \\
% Linear(4,1) & 1 \\
% Sigmoid & 1 \\
% \hline %inserts single line
% \end{tabular}
% \label{table:1d_D} % is used to refer this table in the text
% \end{table}

\begin{table}[h]
\caption{\textbf{ResBlock}} % title of Table
\centering % used for centering table
\begin{tabular}{c} % centered columns (4 columns)
\toprule
\textbf{F(x)}\\\midrule
Linear\\ % inserting body of the table
ReLU() \\
Linear\\
\bottomrule %inserts single line
\end{tabular}
\label{table:resblock} % is used to refer this table in the text
\end{table}

\begin{table}[h]
\caption{\textbf{Generator for 1D setting}} % title of Table
\centering % used for centering table
\begin{tabular}{l c c}
%  \hline
\toprule
\textbf{Layer} & \textbf{Neurons} & \textbf{Num Layers} \\ \midrule
Linear & 10 $\rightarrow$ 4 & 1  \\ %\midrule
ResBlock & 4 & 16 \\ 
Linear & 4$\rightarrow$ 1 & 1 \\ 
\bottomrule %inserts single line
\end{tabular}
\label{table:1d_G} % is used to refer this table in the text
\end{table}

\begin{table}[ht]
\caption{\textbf{Discriminator for 1D setting}} % title of Table
\centering % used for centering table
\begin{tabular}{l c c}
%  \hline
\toprule
\textbf{Layer} & \textbf{Neurons} & \textbf{Num Layers} \\ \midrule
Linear & 1 $\rightarrow$ 4 & 1  \\ %\midrule
ResBlock & 4 & 16 \\ 
Linear & 4 $\rightarrow$ 1 & 1 \\
Sigmoid & 1 & 1 \\
\bottomrule %inserts single line
\end{tabular}
\label{table:1d_D} % is used to refer this table in the text
\end{table}

% \section{User Study (User Interface):}
% In order to analyze how users perceive the effects of different components of the user interface, we conducted a pilot study with 14 participants who were all graduate students of computer science in the age group of 20-30 and about 30\% of them women and 70\% men with little to no artistic experience. 
% % \todo{who were all graduate students in computer science, with little to no artistic experience. (or something like that, you usually see age range/gender/where we sourced them written out here)}. 
% We attempted to study three main variables: \textbf{outlines vs edges, interactivity vs no interactivity, and completion hints vs no completion hints.} 
% Each participant was instructed to use each variant of our system, presented in a random order, in order to generate realistic images from 5 random classes. 
% Each user was asked to rate his/her performance on the NASA Task Load Index (lower the better). \cite{hart1988development}. 


% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{user_study/barplots.pdf}
%     \caption{{\bf NASA TLX Score Comparisons (lower is better): }
%     The NASA TLX Questionnaire consists of 6 different subjective scales the raw scores for the various interfaces are depicted in the figure, the aggregate is computed using the weight of each subjective subscale using a pair-wise importance ranking performed by the subject. We see that our full system systematically obtains the lowest scores in all the subjective subscales while the one with the dense edge inputs obtains the highest.\label{fig:nasa-tlx}
%     \vspace{-2mm}
%     }
%     \vspace{-2mm}
% \end{figure*}

% \begin{table*}[h]
% \resizebox{\linewidth}{!}{
% \caption{\textbf{User Study: User Interfaces}} % title of Table
% \centering % used for centering table
% \begin{tabular}{l c c c c}
% %  \hline
% \toprule
% \textbf{Interface} & \textbf{Input} & \textbf{Recommendation} &  \textbf{Interactive} & \textbf{Mean Aggregate Score} \\ \midrule
% Non Interactive & Outline & \checkmark &  & 29.01\\ %\midrule
% Dense Edge Inputs & Edge & \checkmark & \checkmark & 47.50 \\ 
% No outline completion & Outline & & \checkmark & 28.29\\ 
% \textbf{Our Full System} & \textbf{Outline} & \textbf{\checkmark} & \textbf{\checkmark} & \textbf{20.83} \\
% \bottomrule %inserts single line
% \end{tabular}
% \label{table:user_study} % is used to refer this table in the text
% }
% \end{table*}

% % \begin{itemize}
% %     \item \textbf{A:} Backend: 2-stage, Input type: Outline, with recommendation, no interactivity
% %     \item \textbf{B:} Backend: 2-stage, Input type: Edge, with recommendation, with interactivity
% %     \item \textbf{C:} Backend: 2-stage, Input type: Outline, no recommendation, with interactivity 
% %     \item \textbf{D:} Backend: 2-stage, Input type: Outline, with recommendation, with interactivity 
% % \end{itemize}




% \subsection{NASA TLX: Details}
% NASA TLX questionnaire \cite{hart1988development} is a standard questionnaire used by psychological studies which gauges workload of a task on 6 metrics namely: Mental Demand, Physical Demand, Temporal Demand, Performance, Effort and Frustration. Since different people interpret these terms differently first they are provided with a pairwise comparison of each of the terms being the most important contributor to the workload for the given task. The ratings on each of these scales are weighted by the relative importance (obtained from the pairwise comparisons) and averaged out to get a score from 0-100 which represents the workload for the current task (lower is better).

% \tabref{table:user_study} shows the mean aggregate scores obtained for each interface, aggregate scores are obtained by weighting each subjective score on the individual metric by the user's pairwise importance ranking. For a more detailed analysis into the individual metrics please refer to \figref{fig:nasa-tlx} which provides the raw scores (unweighted) for each individual metric.



% % \begin{table}[ht]
% % \caption{\textbf{User Study: User Interface} NASA TLX Index Mean \textbf{(Aggregate)} scores (lower is better)} % title of Table
% % \centering % used for centering table
% % \begin{tabular}{l c}
% % %  \hline
% % \toprule
% % \textbf{Interface} & \textbf{Mean}  \\ \midrule
% % Non Interactive & Outline & 29.01 \\ %\midrule
% % Dense Edge Inputs & 47.50 \\ 
% %  & 28.29 \\ 
% % \textbf{D} & \textbf{20.83}\\
% % \bottomrule %inserts single line
% % \end{tabular}
% % \label{table:user_study} % is used to refer this table in the text
% % \end{table}

% As depicted in \tabref{table:user_study} and \figref{fig:nasa-tlx} we can see that:

% \begin{itemize}
%     \item \textbf{Outlines vs Edges:} Mean score for Our Full System is lesser than Dense Edge Inputs thus indicating that users prefer a model trained with outlines compared to one trained with edges.
%     \item \textbf{Interactivity vs No Interactivity:} Mean score for No outline completion and Our Full System which are outline based but has interactivity shows lower scores than Non Interactive which doesn't have interactivity. This shows that users prefer interactivity to non-interactivity.
%     \item \textbf{Sketch Recommendation vs No Sketch Recommendation:} Mean score for Our Full System which has outline-completion based recommendation for the sketch are lower than for No outline completion thus indicating that users prefer recommended outlines over no outline recommendation.
% \end{itemize}

% A further larger scale study might be needed to fully validate the hypotheses. However, this pilot study shows that a recommendation system (sketch completion) where the outline completion is shown along along with the corresponding generated image, was given the highest preference by the users.

% \begin{figure}[t]
%     \centering
%     % \includegraphics[width=\linewidth]{images/shape_completion/shape_completion.pdf}
%     \includegraphics[width=\linewidth]{paper_images/shapedis.pdf}
%     \vspace{-8mm}
%     \caption{\textbf{First stage (Shape Discriminator)} To achieve multi-modal completions, the shape discriminator is designed using inspiration from non-image conditional model \cite{mescheder2018training} with the conditioning input provided at multiple scales, so that the discriminator network doesn't ignore the partial stroke conditioning.
%     %$G_S$ design inspired from unconditional generator, with the conditioning provided at multiple scales to $G_S$ and $D_S$
%     }\label{fig:SketchDisNet}
%     %\vspace{-2mm}
% \end{figure}

\section{Shape Completion Details}

% The Bicycle GAN model \cite{zhu2017toward} was used to train the shape completion model with minor modifications. In order for the BicycleGAN model to generate the shape completion appropriate for the correct class the class condition was concatenated to the input as a one hot encoding in the Generator, Discriminator and the Encoder. Since the class condition worked decently we didn't try introducing gating in those scenarios but it can potentially be introduced although the gating might potentially produce multimodal results. The input domain images for the model consisted of the partial versions of the sketches or outlines and the target domain for the model consisted of the completed sketches or outlines. 

For shape completion, training and testing inputs were created using by placing occluders of 3 sizes (64$\times$64, 128$\times$128, 192$\times$192) on top of full sketches or outlines.
For each size, 25 partial sketches/outlines were created by random placement of the occluder, thus leading to 75 partial versions to be completed from a single sketch/outline. 


\begin{table}[h]
\caption{\textbf{Shape Generator}} % title of Table
\centering % used for centering table
\begin{tabular}{l c c}
%  \hline
\toprule
\textbf{Layer} & \textbf{Output Size} & \textbf{Filter} \\ \midrule
\small{Fully Connected} & \small{$512 \times 4 \times 4$} & \small{$256 \rightarrow 512 \times 4 \times 4$} \\
\small{Reshape} & \small{$512 \times 4 \times 4$} & - \\
\midrule
\small{Resnet-Block} & \small{$512 \times 4 \times 4$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Resnet-Block} & \small{$512 \times 4 \times 4$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Sparse-Resnet-Block} & \small{$512 \times 4 \times 4$} & \small{$1 \rightarrow 512 \rightarrow 512$} \\
\small{NN-Upsampling} & \small{$512 \times 8 \times 8$} & - \\
\midrule
\small{Resnet-Block} & \small{$512 \times 8 \times 8$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Resnet-Block} & \small{$512 \times 8 \times 8$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Sparse-Resnet-Block} & \small{$512 \times 8 \times 8$} & \small{$1 \rightarrow 512 \rightarrow 512$} \\
\small{NN-Upsampling} & \small{$512 \times 16 \times 16$} & - \\
\midrule
\small{Resnet-Block} & \small{$256 \times 16 \times 16$} & \small{$512 \rightarrow 256 \rightarrow 256$} \\
\small{Resnet-Block} & \small{$256 \times 16 \times 16$} & \small{$256 \rightarrow 256 \rightarrow 256$} \\
\small{Sparse-Resnet-Block} & \small{$256 \times 16 \times 16$} & \small{$1 \rightarrow 256 \rightarrow 256$} \\
\small{NN-Upsampling} & \small{$256 \times 32 \times 32$} & - \\
\midrule
\small{Resnet-Block} & \small{$128 \times 32 \times 32$} & \small{$256 \rightarrow 128 \rightarrow 128$} \\
\small{Resnet-Block} & \small{$128 \times 32 \times 32$} & \small{$128 \rightarrow 128 \rightarrow 128$} \\
\small{Sparse-Resnet-Block} & \small{$128 \times 32 \times 32$} & \small{$128 \rightarrow 128 \rightarrow 128$} \\
\small{NN-Upsampling} & \small{$128 \times 64 \times 64$} & - \\
\midrule
\small{Resnet-Block} & \small{$64 \times 64 \times 64$} & \small{$128 \rightarrow 64 \rightarrow 64$} \\
\small{Resnet-Block} & \small{$64 \times 64 \times 64$} & \small{$64 \rightarrow 64 \rightarrow 64$} \\
\small{Sparse-Resnet-Block} & \small{$64 \times 64 \times 64$} & \small{$1 \rightarrow 64 \rightarrow 64$} \\
\small{NN-Upsampling} & \small{$64 \times 128 \times 128$} & - \\
\midrule
\small{Resnet-Block} & \small{$32 \times 128 \times 128$} & \small{$64 \rightarrow 32 \rightarrow 32$} \\
\small{Resnet-Block} & \small{$32 \times 128 \times 128$} & \small{$32 \rightarrow 32 \rightarrow 32$} \\
\small{Conv2D} & \small{$1 \times 128 \times 128$} & \small{$ 64 \rightarrow 1$} \\
\bottomrule %inserts single line
\end{tabular}
\label{table:G_S} % is used to refer this table in the text
\end{table}


\begin{table}[h]
\caption{\textbf{Shape Discriminator}} % title of Table
\centering % used for centering table
\begin{tabular}{l c c}
%  \hline
\toprule
\textbf{Layer} & \textbf{Output Size} & \textbf{Filter} \\ \midrule
\small{Conv2D} & \small{$32 \times 128 \times 128$} & \small{$2 \rightarrow 32$} \\
\midrule
\small{Resnet-Block} & \small{$32 \times 128 \times 128$} & \small{$32 \rightarrow 32 \rightarrow 32$} \\
\small{Resnet-Block} & \small{$64 \times 128 \times 128$} & \small{$32 \rightarrow 32 \rightarrow 64$} \\
\small{Sparse-Resnet-Block} & \small{$64 \times 128 \times 128$} & \small{$2 \rightarrow 128 \rightarrow 128$} \\
\small{Avg-Pool2D} & \small{$64 \times 64 \times 64$} & - \\
\midrule
\small{Resnet-Block} & \small{$64 \times 64 \times 64$} & \small{$64 \rightarrow 64 \rightarrow 64$} \\
\small{Resnet-Block} & \small{$128 \times 64 \times 64$} & \small{$64 \rightarrow 64 \rightarrow 128$} \\
\small{Sparse-Resnet-Block} & \small{$128 \times 64 \times 64$} & \small{$2 \rightarrow 64 \rightarrow 64$} \\
\small{Avg-Pool2D} & \small{$128 \times 32 \times 32$} & - \\
\midrule
\small{Resnet-Block} & \small{$128 \times 32 \times 32$} & \small{$128 \rightarrow 128 \rightarrow 128$} \\
\small{Resnet-Block} & \small{$256 \times 32 \times 32$} & \small{$128 \rightarrow 128 \rightarrow 256$} \\
\small{Sparse-Resnet-Block} & \small{$256 \times 32 \times 32$} & \small{$2 \rightarrow 256 \rightarrow 256$} \\
\small{Avg-Pool2D} & \small{$256 \times 16 \times 16$} & - \\
\midrule
\small{Resnet-Block} & \small{$256 \times 16 \times 16$} & \small{$256 \rightarrow 256 \rightarrow 256$} \\
\small{Resnet-Block} & \small{$512 \times 16 \times 16$} & \small{$256 \rightarrow 256 \rightarrow 512$} \\
\small{Sparse-Resnet-Block} & \small{$512 \times 16 \times 16$} & \small{$2 \rightarrow 512 \rightarrow 512$} \\
\small{Avg-Pool2D} & \small{$512 \times 8 \times 8$} & - \\
\midrule
\small{Resnet-Block} & \small{$512 \times 8 \times 8$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Resnet-Block} & \small{$512 \times 8 \times 8$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Sparse-Resnet-Block} & \small{$512 \times 8 \times 8$} & \small{$2 \rightarrow 512 \rightarrow 512$} \\
\small{Avg-Pool2D } & \small{$512 \times 4 \times 4$} & - \\
\midrule
\small{Resnet-Block} & \small{$512 \times 4 \times 4$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Resnet-Block} & \small{$512 \times 4 \times 4$} & \small{$512 \rightarrow 512 \rightarrow 512$} \\
\small{Fully Connected} & \small{$N_{classes}$} & \small{\small{$ 512 \cdot 4 \cdot 4 \rightarrow N_{classes}$}} \\
% \small{Fully Connected} & \small{$N_{classes}$} & - \\
\bottomrule %inserts single line
\end{tabular}
\label{table:D_S} % is used to refer this table in the text
\end{table}


The generator architecture for the shape completion is depicted in table \tabref{table:G_S} while the discriminator architecture is depicted in table \tabref{table:D_S}. 
The architecture is almost the same as \cite{mescheder2018training} except for the sparse Resnet blocks used for injecting conditioning via multiple scales. 
The sparse Resnet blocks first resize the input conditioning (for example, the partial user strokes), and then convert the feature map into the correct number of channels using a Resnet block to add to the feature activation.
This occurs just prior to the upsampling step in the generator and just prior to the avg pool step in the discriminator. 
%This symmetric architecture was adopted to keep the parameters of the generator and the discriminator similar to stabilize training.


% \section{Appearance Generation Details}
% For more details about the various architectures described in Section 4.2 in the main paper, we show the schematic representation of all the above mentioned models in \figref{fig:arch-inj} and Figure 5 in the main paper.

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{paper_images/arch_inject2.pdf}
%     \caption{{\bf Conditioning injection variants.}
%     Image conditioning can be naively incorporated in a generator through simple concatenation in {\bf (left)} the input layer only or {\bf (mid-left)} in all layers. {\bf (mid)} The network can be further encouraged to use the conditioning through a learned network, using either a classification objective for categorical conditioning~\cite{odena2016conditional,chen2016infogan} or a regression objective for continuous conditioning. {\bf (Mid-right)} We train a network on the conditioner to predict parameters which guide softly-gated units in the main network. {\bf (Right)} These conditioning options can be correspondingly applied to a discriminator. We propose using soft-gating on the discriminator as well.\label{fig:arch-inj}
%     \vspace{-2mm}
%     }
%     \vspace{-2mm}
% \end{figure*}

\begin{figure*}[t]
\centering
\begin{tabular}{*{3}{c@{\hspace{3px}}}}
\textbf{Blockwise Gating} & \textbf{Channelwise Gating} \vspace{-1mm} & \\
\includegraphics[height=3.35cm,trim={.15cm 0 0 .4cm}, clip]{paper_images/alphas_block.pdf} &
\includegraphics[height=3.35cm,trim={0 0 0 .4cm}, clip]{paper_images/alphas_chan.pdf} & 
\includegraphics[height=3.35cm,trim={5.8cm 0 .2cm .4cm}, clip]{paper_images/alpha_legend.pdf}
\\
\end{tabular}
\vspace{-2mm}
\caption{\label{fig:alpha_heat}
\textbf{Learned gating parameters.} We show the soft-gating parameters for {\bf (left)} blockwise and {\bf (right)} channelwise gating for the {\bf (top)} generator and {\bf (bot)} discriminator. Black indicates
% $\alpha=0$, or
completely off, and white indicates
% $\alpha=1$, or 
completely on. For channelwise, a subset (every 4th) of blocks is shown. Within each block, channels are sorted in ascending order of the first category. The nonuniformity of each columns indicates that different channels are used more heavily for different classes.
\vspace{-3mm}
}
\vspace{-2mm}
\end{figure*}

% \begin{figure*}[t]
%     \centering
%     % \includegraphics[width=\linewidth]{paper_images/arch_gate.pdf}
%     \includegraphics[width=.9\linewidth]{paper_images/arch_gate2.pdf}
%     \caption{
%     % {\bf Incorporating soft-gating into residual blocks.} \rz{Order got changed, may or may not need to add key for hadamard product}
%     {\bf (Top-left)} A ``vanilla" residual block without gated conditioning parameters modifies input tensor $X$ into $X+\mathcal{H}(X)$. Conditioning with concatenation uses this setup. {\bf (Top-mid)} The $\mathcal{H}(X)$ block is softly-gated by scalar parameter $\alpha$ and shift $\beta$. {\bf (Top-right)} Only the gating is used, without bias. {\bf (Bot-left)} Adaptive Instance Normalization~\cite{huang2017arbitrary} applies a channel-wise scaling and shifting after an instance normalization layer. {\bf (Bot-mid)} Channel-wise gating adds restrictions to the range of $\mbox{\boldmath $\alpha$}$. {\bf (Bot-right)} We find that channel-wise gating (without added bias) to empirically produce the best results.\label{fig:arch-gate}
%     \vspace{-2mm}
%     }
%     % \vspace{-4mm}
% \end{figure*}




% \section{1D Mixture of Gaussians Dataset}
% % In order to understand the behavior of the various residual blocks, we first perform a very simple synthetic experiment, much easier than generating high-dimensional complex images.
% We consider a 1D mixture of Gaussians with five components with modes at 10, 20, 60, 80 and 110, and standard deviations of 3, 3, 2, 2 and 1, respectively. While the first two modes overlap significantly, the fifth mode stands isolated as shown in Figure 6 of the main paper.
% % \figref{fig:onedexperiment}. 
% We train our Resnet block based GAN model using 1 million samples from this distribution and generate 1 million samples from the trained model. In order to compare the learned distribution with the ground truth distributions, we estimate the learned distribution by computing histograms over the data points. 
% %These histograms are carefully created using different bin sizes and the best bin (found to be 0.1) is chosen. 
% %The generated distribution from the trained model corresponds very closely to the ground truth distribution. 
% As shown in 
% % \figref{fig:onedexperiment}
% Figure 6 in the main paper, the generated distribution closely matches the ground truth one, and we can observe that  residual blocks focus on specific modes, which motivates our gating mechanism.





\section{Outline$\rightarrow$Image Network Architecture}
The network architecture is based on our observations that deeper, narrower networks perform better when capturing multi-modal data distributions. 
The second guiding principle in the design of the architecture is that the different blocks should have similar number of channels so that the gating hypernetwork can distribute the modes between the blocks efficiently. 
Finally, we apply gating to the residual blocks responsible for upsampling and downsampling as well, in order to allow for better fine-grained control on the generation process. 
\tabref{table:convresblock} shows the Convolution Residual Block which does not change the spatial resolution of the activation volume, 
\tabref{table:downconvresblock} shows the Downsampling Residual Block which reduces the activation volume to half the spatial resolution, 
\tabref{table:upconvresblock} shows the Upsampling Residual Block which increases the activation volume to twice the spatial resolution.
In the case of gating (either block wise/channel-wise) the gating is applied on the $F(x)$ of each network. 
The shortcut branch represented in \tabref{table:upconvresblock} and \tabref{table:downconvresblock} represents the branch of the Resnet which is added to $F(x)$ branch. In these scenarios since the resolution of $x$ changes in $F(x)$, the shortcut also has a similar upsampling/downsampling layer.


\begin{table}[ht]
    \makegapedcells
        \centering % used for centering table
        \begin{tabular}{c} % centered columns (4 columns)
        % \hline\hline %inserts double horizontal lines
        \toprule
        \textbf{F(x)}\\%heading
        \midrule
        Conv2d \\
        InstanceNorm\\ % inserting body of the table
        ReLU() \\
        Conv2d \\
        InstanceNorm\\ % inserting body of the table
        ReLU() \\
        \bottomrule %inserts single line
        \end{tabular}
        \caption{\textbf{ConvResblock}} % title of Table
        \label{table:convresblock} % is used to refer this table in the text
\end{table}

\begin{table}
        \centering % used for centering table
        \begin{tabular}{c} % centered columns (4 columns)
        \toprule % \hline\hline %inserts double horizontal lines
        \textbf{F(x)}\\%heading
        \midrule % \hline
        Upsample (Nearest Neighbor) \\
        ReflectionPad \\
        Conv2d \\
        InstanceNorm\\ % inserting body of the table
        ReLU() \\
        Conv2d \\
        InstanceNorm\\ % inserting body of the table
        ReLU() \\
        \midrule % \hline %inserts single line
        \textbf{Shortcut Branch}\\
        \midrule % \hline 
        Upsample (Bilinear) \\
        ReflectionPad\\
        Conv2d \\
        \bottomrule % \hline
        \end{tabular}
        \caption{        \label{table:upconvresblock} \textbf{UpConvResblock}} % title of Table
\end{table}

\begin{table}
        \centering % used for centering table
        \begin{tabular}{c} % centered columns (4 columns)
        \toprule % \hline\hline %inserts double horizontal lines
        \textbf{F(x)}\\%heading
        \midrule
        Avgpool 2d \\
        ReflectionPad \\
        Conv2d \\
        InstanceNorm\\ % inserting body of the table
        ReLU() \\
        Conv2d \\
        InstanceNorm\\ % inserting body of the table
        ReLU() \\
        \midrule% \hline %inserts single line
        \textbf{Shortcut Branch}\\
        \midrule % \hline 
        Avgpool 2d \\
        ReflectionPad\\
        Conv2d \\
        \bottomrule% \hline
        \end{tabular}
        \caption{\label{table:downconvresblock} \textbf{DownConvResblock}} 
\end{table}


\begin{table}[ht]
\caption{\textbf{Gated Resnet G: Scribble Dataset}}
\centering % used for centering table
\begin{tabular}{l c c} % centered columns (4 columns)
\toprule% \hline
\textbf{Layer} & \textbf{Filter} & \textbf{Num Layers} \\
\midrule
Conv2d & 3 $\rightarrow$ 32 & 1\\
InstanceNorm & 32 & 1 \\ % inserting body of the table
ReLU() & 32 & 1\\
\hdashline% \hline %inserts single line
\textbf{Gated}-ConvResBlock & 32 & 3\\
\textbf{Gated}-DownConvResBlock & 32 & 3\\
\textbf{Gated}-ConvResBlock & 32 & 12\\
\textbf{Gated}-UpConvResBlock & 32 & 3\\
\textbf{Gated}-ConvResBlock & 32 & 3\\
\hdashline
Conv2d & 32$\rightarrow$3 & 1 \\
Tanh() & 3 & 1 \\
\bottomrule% \hline
\end{tabular}
\label{table:resnet_g_scribble} % is used to refer this table in the text
\end{table}

\begin{table}[ht]
\caption{\textbf{Gated Resnet D: Scribble Dataset}}
\centering % used for centering table
\begin{tabular}{l c c} % centered columns (4 columns)
\toprule% \hline
\textbf{Layer} & \textbf{Filter} & \textbf{Num Layers} \\
\midrule
Conv2d & 6 $\rightarrow$ 32 & 1\\
\hdashline% \hline %inserts single line
\textbf{Gated}-ConvResBlock & 32 & 3\\
\textbf{Gated}-DownConvResBlock & 32 & 4\\
\textbf{Gated}-ConvResBlock & 32 & 17\\
\hdashline
Conv2d & 32$\rightarrow$1 & 1 \\
Sigmoid() & 1 & 1 \\
\bottomrule% \hline
\end{tabular}
\label{table:resnet_d_scribble} % is used to refer this table in the text
\end{table}


\begin{table}[ht]
\caption{\textbf{Gating Hypernetwork} $dim^{gate}$ is the number of blocks in the case of Block Wise Gating and the number of channels in the case of Channel Wise Gating. In case of affine its twice of each since the $\beta$ is of the same dimension }
\centering % used for centering table
\begin{tabular}{l c c} % centered columns (4 columns)
\toprule% \hline
\textbf{Layer} & \textbf{Filter/Shape} & \textbf{Num Layers} \\
\midrule
Embedding & $dim^{embed}$ & 1 \\
Conv1d & 1 $\rightarrow$ 16 & 1\\
% \hdashline% \hline %inserts single line
ResBlock1D & 16 & 16\\
Reshape & 16$\times dim^{embed}$ & 1\\
Linear & 16$\times dim^{embed} \rightarrow dim^{gate} $& 1\\
\bottomrule% \hline
\end{tabular}
\label{table:resnet_gating} % is used to refer this table in the text
\end{table}

% \begin{table}[ht]
% \caption{\textbf{Gated Resnet G:Multi-Task Dataset}}
% \centering % used for centering table
% \begin{tabular}{l c c} % centered columns (4 columns)
% \toprule% \hline
% \textbf{Layer} & \textbf{Filter} & \textbf{Num Layers} \\
% \midrule
% Conv2d & 3 $\rightarrow$ 64 & 1\\
% InstanceNorm & 64 & 1 \\ % inserting body of the table
% ReLU() & 64 & 1\\
% \hdashline% \hline %inserts single line
% \textbf{Gated}-ConvResBlock & 64 & 3\\
% \textbf{Gated}-DownConvResBlock & 64 & 3\\
% \textbf{Gated}-ConvResBlock & 64 & 4\\
% \textbf{Gated}-UpConvResBlock & 64 & 3\\
% \textbf{Gated}-ConvResBlock & 64 & 3\\
% \hdashline
% Conv2d & 64$\rightarrow$3 & 1 \\
% Tanh() & 3 & 1 \\
% \bottomrule% \hline
% \end{tabular}
% \label{table:resnet_g_multitask} % is used to refer this table in the text
% \end{table}

% \begin{table}[ht]
% \caption{\textbf{Gated Resnet D:Multi-Task Dataset}}
% \centering % used for centering table
% \begin{tabular}{l c c} % centered columns (4 columns)
% \toprule% \hline
% \textbf{Layer} & \textbf{Filter} & \textbf{Num Layers} \\
% \midrule
% Conv2d & 6 $\rightarrow$ 64 & 1\\
% \hdashline% \hline %inserts single line
% \textbf{Gated}-ConvResBlock & 64 & 3\\
% \textbf{Gated}-DownConvResBlock & 64 & 4\\
% \textbf{Gated}-ConvResBlock & 64 & 9\\
% \hdashline
% Conv2d & 64$\rightarrow$1 & 1 \\
% Sigmoid() & 1 & 1 \\
% \bottomrule% \hline
% \end{tabular}
% \label{table:resnet_d_multitask} % is used to refer this table in the text
% \end{table}


\begin{figure}
    \centering
    \includegraphics{paper_images/hypernet.pdf}
    \caption{Gating Hypernetwork architecture.}
    \label{fig:gating_arch}
\end{figure}

\subsection{Gating Hypernetwork}
The gating hypernetwork was also designed using Resnet blocks. We use 1D convolutions in the Resnet block \tabref{table:resblock1D} to reduce the number of parameters and use BatchNormalization to speed up the training of the network responsible for prediction gating parameters. 
Class conditioning is first passed through an embedding layer to obtain a representation of the class which is further processed by the Resnet blocks. 
The same network is used for the various forms of gating. In case of block wise gating, the number of outputs $dim^{gate}$ for this network is equal to the number of blocks used in the main network.
In the case of an affine transformation, the network predicts an equal number of biases for each the block. 
In the case of channel-wise gating, the number of predicted parameters $dim^{gate}$ is equal to $num^{channels}\times num^{blocks}$ since each residual block consists of equal number of channels.
$\alpha$ was constrained between 0 and 1 corresponding to selecting or rejecting a block, while the $\beta$ was restricted between -1 and 1 when used. 
In the original AdaIN case, parameters are unrestricted, but we found we had to constrain parameters between -1 and 1 in order for the network to perform well. 

\begin{table}[ht]
\caption{\textbf{ResBlock1D}} % title of Table
\centering % used for centering table
\begin{tabular}{c} % centered columns (4 columns)
\toprule
\textbf{F(x)}\\\midrule
Conv1D\\ % inserting body of the table
BatchNorm1D\\
ReLU \\
Conv1D\\
BatchNorm1D\\
ReLU \\
\bottomrule %inserts single line
\end{tabular}
\label{table:resblock1D} % is used to refer this table in the text
\end{table}







% \section{Multimodal Generation (InfoGAN with variations)}
% \label{sec:multimodal}


% Inter-class variation, also called diversity, is a significant challenge in GAN image generation applications. 
% In the pix2pix setting, as shown by previous works \cite{ghosh2017multi} and \cite{zhu2017toward} even the InfoGAN (cLR in \cite{zhu2017toward}) setup was not able to produce meaningful variations (irrespective of the variations in the conditioning), and additional generators or cyclical losses were required to produce meaningful variations in the generated images. 
% With our gating mechanism, we show that we can create meaningful variations, using just the InfoGAN objective.
% This can be seen in the results \figref{fig:infogan_gate} and from the LPIPS metric \cite{zhang2018unreasonable} in  Table. \ref{table:infogan_lpips} which measures the diversity among the generations in the feature space of a standard Imagenet classifier.
% % Since InfoGAN maximizes mutual information, we argue that gating provides a mechanism to effectively optimize it by making the conditioning an active part of the generation process (refer Sec.~\ref{sec:infoGAN}).

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=\linewidth]{infogan.jpg}
%     \caption{{\bf Edges$\rightarrow$Handbags qualitative examples.} Naive Conditioning of InfoGAN fails (left) while gating (right) succeeds in producing diverse generations.
%     \vspace{-5mm}
%     }\label{fig:infogan_gate}
%     % \vspace{-2mm}
% \end{figure}
% \begin{table}[h]
%     \centering
%         \begin{tabular}{l c}
%         % \hline
%         \toprule
%         \textbf{Model} & \textbf{LPIPS Distance} \\ \midrule
%         Random Real Images & $0.3665 \pm 0.0053$ \\ \midrule
%         BicycleGAN~\cite{zhu2017toward} & $0.1374 \pm 0.0005$  \\ \midrule
%         Concat(In) &  $0.0432 \pm 0.0002$ \\
%         Concat(All) & $0.0159 \pm 0.0004$ \\ \cdashline{1-2}
%         ChannelGate [Ours] & $0.0964 \pm 0.0003$  \\
%         \bottomrule %inserts single line
%         \end{tabular}
%     \caption{\label{table:infogan_lpips} {\bf Edges$\rightarrow$Handbags Diversity.} LPIPSv0.1~\cite{zhang2018unreasonable} distance between randomly generated handbags, given the same edge map, as proposed in~\cite{zhu2016generative}. Given the same architecture, gating achieves higher diversity than concatenation.}
% \end{table}



% % \begin{figure*}[t]
% %     \centering
% %     \includegraphics[width=\linewidth,trim={2.6cm 0 1.8cm 0},clip]{paper_images/mog.pdf}
% %     % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
% %     \caption{{\bf 1D Mixture of Gaussians.} {\bf (Left)} Samples from a residual network (blue-dotted) closely approximate the training distribution (black). {\bf (Mid)} Removing one residual block removes one mode of the predicted distribution. {\bf (Right)} Removing two blocks drops two modes. Note that samples stay mostly ``on-manifold" of the ground truth distribution. {\bf Note:} This is a reproduction of Figure 2 from the main paper, it is included here for completeness.
% %     \vspace{-2mm}
% %     }\label{fig:onedexperiment}
% %     \vspace{-3mm}
% % \end{figure*}

% \subsection{Multimodal Generations: Architecture}
% The network architectures used in this setting are very similar to the ones used for the outline $\rightarrow$ image generation with some small differences. The discriminator and the Q network responsible for the maximization of mutual information are not gated in this case since the class labels are not provided to the discriminator or the Q network. The number of blocks and channels in each block in the case of the generator are more than the case of scribble dataset. The gating hypernetwork also differs slightly since the sampled variables are not only one-hot encoding but a combination of one-hot and gaussian variables, hence we directly use it and bypass the embedding layer.

% \begin{table}[ht]
% \caption{\textbf{Gating Hyper Network(InfoGAN)}
% % nsalient(12) are the number of variables representing
% We have $C=2$ continuous and $K=10$ discrete latent variables. Variable $dim^{gate}$ is the number of channels which are gated. }
% \centering % used for centering table
% \begin{tabular}{l c c} % centered columns (4 columns)
% \toprule% \hline
% \textbf{Layer} & \textbf{Filter/Shape} & \textbf{Num Layers} \\
% \midrule
% Reshape & $K+C$ & 1 \\
% Conv1d & 1 $\rightarrow$ 16 & 1\\
% % \hdashline% \hline %inserts single line
% ResBlock1D & 16 & 16\\
% Reshape & $16\times (K+C)$ & 1\\
% Linear & $16\times (K+C) \rightarrow dim^{gate} $& 1\\
% \bottomrule% \hline
% \end{tabular}
% \label{table:resnet_gating_infogan} % is used to refer this table in the text
% \end{table}

% \begin{table}[ht]
% \caption{\textbf{Gated Resnet G:InfoGAN}}
% \centering % used for centering table
% \begin{tabular}{l c c} % centered columns (4 columns)
% \toprule% \hline
% \textbf{Layer} & \textbf{Filter} & \textbf{Num Layers} \\
% \midrule
% Conv2d & 3 $\rightarrow$ 64 & 1\\
% InstanceNorm & 64 & 1 \\ % inserting body of the table
% ReLU() & 64 & 1\\
% \hdashline% \hline %inserts single line
% \textbf{Gated}-ConvResBlock & 64 & 3\\
% \textbf{Gated}-DownConvResBlock & 64 & 3\\
% \textbf{Gated}-ConvResBlock & 64 & 20\\
% \textbf{Gated}-UpConvResBlock & 64 & 3\\
% \textbf{Gated}-ConvResBlock & 64 & 3\\
% \hdashline
% Conv2d & 64$\rightarrow$3 & 1 \\
% Tanh() & 3 & 1 \\
% \bottomrule% \hline
% \end{tabular}
% \label{table:resnet_g_infogan} % is used to refer this table in the text
% \end{table}


% \begin{table}[ht]
% \caption{\textbf{Resnet D:Infogan}}
% \centering % used for centering table
% \begin{tabular}{l c c} % centered columns (4 columns)
% \toprule% \hline
% \textbf{Layer} & \textbf{Filter} & \textbf{Num Layers} \\
% \midrule
% Conv2d & 6 $\rightarrow$ 64 & 1\\
% \hdashline% \hline %inserts single line
% ConvResBlock & 64 & 3\\
% DownConvResBlock & 64 & 4\\
% ConvResBlock & 64 & 25\\
% \hdashline
% Conv2d & 64$\rightarrow$1 & 1 \\
% Sigmoid() & 1 & 1 \\
% \bottomrule% \hline
% \end{tabular}
% \label{table:resnet_d_infogan} % is used to refer this table in the text
% \end{table}

% \begin{table}[ht]
% \caption{\textbf{Resnet Q:Infogan}}
% \centering % used for centering table
% \begin{tabular}{l c c} % centered columns (4 columns)
% \toprule% \hline
% \textbf{Layer} & \textbf{Filter/Shape} & \textbf{Num Layers} \\
% \midrule
% Conv2d & 6 $\rightarrow$ 64 & 1\\
% \hdashline% \hline %inserts single line
% ConvResBlock & 64 & 3\\
% DownConvResBlock & 64 & 4\\
% ConvResBlock & 64 & 25\\
% \hdashline
% Conv2d & 64$\rightarrow$1 & 1 \\
% Reshape & 225 & 1 \\
% \midrule
% \textbf{Discrete Branch} \\
% \midrule
% Linear & 225 $\rightarrow$ 10 & 1 \\
% \midrule
% \textbf{Continuous Branch($\mu$)} \\
% \midrule
% Linear & 225 $\rightarrow$ 2 & 1 \\
% \midrule
% \textbf{Continuous Branch($\sigma$)} \\
% \midrule
% Linear & 225 $\rightarrow$ 2 & 1 \\
% \bottomrule% \hline
% \end{tabular}
% \label{table:resnet_q_infogan} % is used to refer this table in the text
% \end{table}

% \begin{table}[ht]
% \caption{\textbf{Gated Resnet D:Scribble Dataset}} % title of Table
% \centering % used for centering table
% \begin{tabular}{c} % centered columns (4 columns)
% \hline
% Conv2d(6,64,kernel=3,stride=1,padding=1) \\
% \hline %inserts single line
% 3xGatedConvResBlock(64) \\
% 4xDownGatedConvResBlock(64) \\
% 17xGatedConvResBlock(64) \\
% \hline
% Conv2d(64,1,kernel=3,stride=1,padding=1) \\
% Sigmoid() \\
% \hline
% \end{tabular}
% \label{table:resnet_d_scribble} % is used to refer this table in the text
% \end{table}



% \section{Subset of Comparison of Results:}

% We show the results of our various gating mechanisms along with all the baselines reported in the paper on the Scribble Dataset's subset of test images. These images were the ones used for Amazon Mechanical Turk and the evaluation metrics reported in the paper.
% \href{http://www.robots.ox.ac.uk/~arnabg/all_results_supplementary/index.html}{Comparison of our technique vs all baselines}

\section{Distribution of Alphas}
A histogram of the distribution of the various alphas for the block-wise setting and the channel-wise setting is shown in \figref{fig:alpha_hist}. Even without an explicit sparsity constraint, the alphas are pushed near the extremes. 
%The effect is also demonstrated in the case of the block wise gating, with the channel wise gating parameters being more evenly distributed.
\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth]{alpha_hist.pdf}
    % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
    \caption{We show the distribution of the $\alpha$ values. Typically, they are closer to the extremes (0 or 1) rather than the intermediate values.}
    \label{fig:alpha_hist}
    % \vspace{-3mm}
\end{figure*}

% \section{Interpolations:}
% In order to judge the robustness of the trained models and to analyze the differences between the naive concatenation techniques compared with our gating mechanisms we conduct some inter-class interpolations. As we can see from \figref{fig:inter_watermelon_cookie}, \figref{fig:inter_orange_basketball}, \figref{fig:inter_cookie_moon} and \figref{fig:inter_orange_cupcake} that our gating mechanisms produce smooth transitions between classes while the case of naive concatenation techniques failing to generate basketball at all, thus failing at interpolating between basketball and orange.


% {\small
% \bibliographystyle{ieee}
% \bibliography{src/gatedblocks}
% }

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{interpolation-watermelon-cookie.pdf}
%     % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
%     \caption{{\bf Cookie $\rightarrow$ Watermelon:} As evident from the interpolation the gating produces much smoother transitions than simple concatenation techniques }
%     \label{fig:inter_watermelon_cookie}
%     \vspace{-3mm}
% \end{figure*}


% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{interpolation-orange-basketball.pdf}
%     % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
%     \caption{ {\bf Basketball $\rightarrow$ Orange:} A failure case of the simple conditioning technique, it never generates basketball and hence is not able to interpolate between basketball and orange. }
%     \label{fig:inter_orange_basketball}
%     \vspace{-3mm}
% \end{figure*}

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{interpolation-cookie-moon.pdf}
%     % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
%     \caption{ {\bf Moon $\rightarrow$ Cookie:} Interpolation between moon and cookie }
%     \label{fig:inter_cookie_moon}
%     \vspace{-3mm}
% \end{figure*}

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth]{interpolation-orange-cupcake.pdf}
%     % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
%     \caption{ {\bf Orange $\rightarrow$ Cupcake:} Interpolation between orange and cupcake, in the case of the baseline concat mechanism there's an abrupt transition from orange to cupcake while the transition is much smoother in the case of gated mechanisms }
%     \label{fig:inter_orange_cupcake}
%     \vspace{-3mm}
% \end{figure*}




\begin{figure*}[t]
\centering
\begin{tabular}{*{2}{c@{\hspace{3px}}}}
% \textbf{Blockwise Gating} & \textbf{Channelwise Gating} \vspace{-1mm} \\
% \includegraphics[height=3.35cm,trim={0 0 0 .4cm}, clip]{paper_images/alphas_chan_1.pdf} & 
\includegraphics[height=3.15cm,trim={6.0cm 0 7.6cm .4cm}, clip]{paper_images/alphas_chan_0.pdf} & 
\includegraphics[height=3.15cm,trim={5.8cm 0 .2cm .4cm}, clip]{paper_images/alpha_legend.pdf}
\\
\includegraphics[height=3.15cm,trim={6.0cm 0 7.6cm .4cm}, clip]{paper_images/alphas_chan_8.pdf} & 
\includegraphics[height=3.15cm,trim={5.8cm 0 .2cm .4cm}, clip]{paper_images/alpha_legend.pdf}
\\
\includegraphics[height=3.15cm,trim={6.0cm 0 7.6cm .4cm}, clip]{paper_images/alphas_chan_16.pdf} & 
\includegraphics[height=3.15cm,trim={5.8cm 0 .2cm .4cm}, clip]{paper_images/alpha_legend.pdf}
\\

\end{tabular}
% \vspace{-2mm}
\caption{\label{fig:alpha_heat}
\textbf{Learned channel-wise gating parameters.} We show the soft-gating parameters for channelwise gating for the {\bf (top)} generator and {\bf (bot)} discriminator. Black indicates
% $\alpha=0$, or
completely off, and white indicates
% $\alpha=1$, or 
completely on. We show all 24 blocks. The nonuniformity of each columns indicates that different channels are used more heavily for different classes.
% \vspace{-3mm}
}
% \vspace{-2mm}
\end{figure*}

% \newpage
\section{Unusual Shapes for Various Classes}

% \begin{figure*}[t]
%     \centering
%     \includegraphics[width=\linewidth,trim={0 0 4.5cm 0},clip]{paper_images/supplementary_grid_block.pdf}
%     % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
%     \caption{{\bf Block-Wise Gating:} We observe that the technique extends to not only the shapes it was trained on but can also generate images for some input shapes corresponding to other classes and to the extreme can generate images for certain shapes it never encountered during training such as the triangle and heart were directly downloaded from the internet. }
%     \label{fig:block_shapes}
%     \vspace{-3mm}
% \end{figure*}

As evident from \figref{fig:channel_shapes} 
% ,\figref{fig:block_shapes} 
the gated generative techniques extend to shapes it never was shown while training. 


\begin{figure*}[t]
    \centering
    \includegraphics[width=\linewidth,trim={0 0 4.5cm 0},clip]{paper_images/supplementary_grid_channel.pdf}
    % \includegraphics[width=\linewidth]{paper_images/mog.pdf}
    \caption{{\bf Channel-Wise Gating:} We observe that the technique can also generate images with shapes not seen by that class during training time.}
    \label{fig:channel_shapes}
    % \vspace{-3mm}
\end{figure*}
